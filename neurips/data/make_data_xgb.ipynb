{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import library and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb\n",
    "!pip install rdkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = Path('../../data/raw/train.csv')\n",
    "TEST_CSV = Path('../../data/raw/test.csv')\n",
    "TRAIN_PAR = Path('../../data/raw/train.parquet')\n",
    "TEST_PAR = Path('../../data/raw/test.parquet')\n",
    "\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{TRAIN_PAR}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 300000)\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{TRAIN_PAR}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 300000)\"\"\").df()\n",
    "\n",
    "test = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{TEST_PAR}'))\"\"\").df()\n",
    "\n",
    "test_1 = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{TEST_PAR}')\n",
    "                        OFFSET 0 LIMIT 600000)\"\"\").df()\n",
    "test_2 = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{TEST_PAR}')\n",
    "                        OFFSET 600000 LIMIT 600000)\"\"\").df()\n",
    "test_3 = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{TEST_PAR}')\n",
    "                        OFFSET 1200000 LIMIT 600000)\"\"\").df()\n",
    "\n",
    "\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "display(test_1.head())\n",
    "\n",
    "print(len(test_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create ECFP from SMILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    N_FOLDS = 5\n",
    "    RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame,\n",
    "                 output_path='/',\n",
    "                 is_output: bool=False,\n",
    "                 is_test: bool=False,\n",
    "                 ):\n",
    "        self.df = df\n",
    "        self.output_path = output_path\n",
    "        self.is_output = is_output\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def create_ecfp(self):\n",
    "        if not 'molecule' in self.df.columns:\n",
    "            # Convert SMILES to RDKit molecules\n",
    "            self.df['molecule'] = self.df['molecule_smiles'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "            # Generate ECFPs\n",
    "            def generate_ecfp(molecule, radius=2, bits=1024):\n",
    "                if molecule is None:\n",
    "                    return None\n",
    "                return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n",
    "            \n",
    "            self.df['ecfp'] = self.df['molecule'].progress_apply(generate_ecfp);\n",
    "    \n",
    "    def OneHotEncode_protein(self):\n",
    "        if not 'protein_BRD4' in self.df.columns:\n",
    "            one_hot_encoded = pd.get_dummies(self.df['protein_name'], prefix='protein', dtype=int)\n",
    "            self.df = pd.concat([self.df, one_hot_encoded], axis=1)\n",
    "            \n",
    "    def split_fold(self):\n",
    "        if not 'fold' in self.df.columns:\n",
    "            self.df['fold'] = -1\n",
    "            # object\n",
    "            skf = KFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.RANDOM_SEED)\n",
    "\n",
    "            for i, (_train_index, test_index) in enumerate(skf.split(self.df)):\n",
    "                self.df.loc[test_index, 'fold'] = i\n",
    "                \n",
    "    def create_any_binds(self):\n",
    "        if not 'any_binds' in self.df.columns:\n",
    "            # add column and init as 0\n",
    "            self.df['any_binds'] = 0\n",
    "            # Set 'any_binds' to 1 where 'binds' is 1\n",
    "            self.df.loc[self.df['binds'] == 1, 'any_binds'] = 1\n",
    "            # Propagate 'any_binds' to all rows with the same 'molecule_smiles' value\n",
    "            self.df['any_binds'] = self.df.groupby('molecule_smiles')['any_binds'].transform('max')\n",
    "\n",
    "    def save_df_as_pickle(self):\n",
    "        self.df.to_pickle(self.output_path)\n",
    "        # if self.is_test: # for test\n",
    "        #     columns_to_drop = [\n",
    "        #         'buildingblock1_smiles',\n",
    "        #         'buildingblock2_smiles',\n",
    "        #         'buildingblock3_smiles',\n",
    "        #         'molecule_smiles',\n",
    "        #         'protein_name',\n",
    "        #         'molecule'\n",
    "        #     ]\n",
    "        #     self.df.drop(columns=columns_to_drop, inplace=True)\n",
    "        #     self.df.to_pickle(self.output_path)\n",
    "        # else: # for train\n",
    "        #     self.df.to_pickle(self.output_path)\n",
    "            \n",
    "                        \n",
    "    def main(self):\n",
    "        print('Processing...')\n",
    "        \n",
    "        self.create_ecfp()\n",
    "        self.OneHotEncode_protein()\n",
    "        if not self.is_test:\n",
    "            self.split_fold()\n",
    "            self.create_any_binds()\n",
    "        if self.is_output:\n",
    "            self.save_df_as_pickle()\n",
    "            \n",
    "        print('complete!')\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encoding to tartget column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# maybe 30s at first time\n",
    "Preprocess = Preprocessing(train, output_path='../../data/processed/ecfp_60000_50per.pkl', is_output=False)\n",
    "df_processed = Preprocess.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "display(df_processed[df_processed['binds']==1].head())\n",
    "display(df_processed[df_processed['any_binds']==1].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# # maybe 17m at first time\n",
    "# Preprocess_test = Preprocessing(test_1, output_path='../../data/processed/ecfp_test_1_necessary.pkl', is_output=True, is_test=True)\n",
    "# df_processed = Preprocess_test.main()\n",
    "# Preprocess_test = Preprocessing(test_2, output_path='../../data/processed/ecfp_test_2_necessary.pkl', is_output=True, is_test=True)\n",
    "# df_processed = Preprocess_test.main()\n",
    "# Preprocess_test = Preprocessing(test_3, output_path='../../data/processed/ecfp_test_3_necessary.pkl', is_output=True, is_test=True)\n",
    "# df_processed = Preprocess_test.main()\n",
    "\n",
    "# display(test_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Preprocess_test = Preprocessing(test[test['protein_name']=='BRD4'], output_path='../../data/processed/ecfp_test_BRD4_all.pkl', is_output=True, is_test=True)\n",
    "df_processed = Preprocess_test.main()\n",
    "Preprocess_test = Preprocessing(test[test['protein_name']=='HSA'], output_path='../../data/processed/ecfp_test_HSA_all.pkl', is_output=True, is_test=True)\n",
    "df_processed = Preprocess_test.main()\n",
    "Preprocess_test = Preprocessing(test[test['protein_name']=='BRD4'], output_path='../../data/processed/ecfp_test_sEH_all.pkl', is_output=True, is_test=True)\n",
    "df_processed = Preprocess_test.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
