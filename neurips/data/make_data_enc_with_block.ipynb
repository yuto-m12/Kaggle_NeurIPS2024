{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    PREPROCESS = True\n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-3\n",
    "    WD = 0.05\n",
    "\n",
    "    NBR_FOLDS = 15\n",
    "    SELECTED_FOLDS = [0]\n",
    "\n",
    "    SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    # tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.PREPROCESS:\n",
    "    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n",
    "           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n",
    "           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36, '.':37, ' ': 38}\n",
    "    train_raw = pd.read_parquet('/root/Kaggle_NeurIPS2024/data/raw/train.parquet')\n",
    "    # Filtering the DataFrame for the specific protein_name\n",
    "    filtered_df = train_raw[train_raw['protein_name'] == 'BRD4']\n",
    "\n",
    "    # Concatenating the strings in each row with a space\n",
    "    smiles = filtered_df.apply(lambda row: ' '.join([\n",
    "        row['molecule_smiles'], \n",
    "        row['buildingblock1_smiles'], \n",
    "        row['buildingblock2_smiles'], \n",
    "        row['buildingblock3_smiles']\n",
    "    ]), axis=1).values\n",
    "\n",
    "#     buildingblock1_smiles\tbuildingblock2_smiles\tbuildingblock3_smiles\n",
    "    # assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n",
    "    # assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n",
    "    def encode_smile(smile):\n",
    "        tmp = [enc[i] for i in smile]\n",
    "        tmp = tmp + [0]*(320-len(tmp))\n",
    "        return np.array(tmp).astype(np.uint8)\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(320)])\n",
    "    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "    train.to_parquet('/root/Kaggle_NeurIPS2024/data/processed/train_enc_withblock.parquet')\n",
    "\n",
    "    test_raw = pd.read_parquet('/root/Kaggle_NeurIPS2024/data/raw/test.parquet')\n",
    "    smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(320)])\n",
    "    test.to_parquet('/root/Kaggle_NeurIPS2024/data/processed/test_enc_withblock.parquet')\n",
    "\n",
    "else:\n",
    "    train = pd.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet')\n",
    "    test = pd.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
