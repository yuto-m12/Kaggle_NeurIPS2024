{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import joblib \n",
    "import shutil\n",
    "from time import time\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "import duckdb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "from torch.nn import BCELoss\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import timm\n",
    "from mamba_ssm import Mamba\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# use one device only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20000_50per_CLM.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TRAIN_CLM_PATH = Path('../../data/processed/20000_50per_CLM.parquet')\n",
    "    TEST_ENC_PATH = Path('../../data/external/test_enc.parquet')\n",
    "    TRAIN_PATH = Path('../../data/raw/train.parquet')\n",
    "    TEST_PATH = Path('../../data/raw/test.parquet')\n",
    "    folds = 2\n",
    "    max_epoch = 9             # number of max epoch. 1epoch means going around the training dataset.\n",
    "    batch_size = 8           # batch size. Number of samples passed to the network in one training step\n",
    "    lr = 1.0e-03              # learning rate. determine step size when updating model's weight\n",
    "    weight_decay = 1.0e-02    # weight decay. Append regularization term for prevent over fitting\n",
    "    es_patience = 5           # Timing for early stopping. If there is no improvement within this number of epochs, training will be stopped early.\n",
    "    seed = 1086               # Random number seed\n",
    "    deterministic = True      # Enable/disable deterministic behavior. If enabled, the program will produce the same results every time it starts with the same initial conditions and inputs.\n",
    "    enable_amp = False        # Enable/disable Automatic Mixed Precision. Optimizations for floating point etc.\n",
    "    device = \"cuda\" \n",
    "    n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(CFG.TRAIN_ENC_PATH)\n",
    "# test = pd.read_parquet(CFG.TEST_ENC_PATH)\n",
    "# train.head()\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train.head())\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = con.query(f\"\"\"(SELECT *\n",
    "#                         FROM parquet_scan('{CFG.TRAIN_PATH}')\n",
    "#                         LIMIT 60000)\"\"\").df()\n",
    "# test = con.query(f\"\"\"(SELECT *\n",
    "#                         FROM parquet_scan('{CFG.TRAIN_ENC_PATH}')\n",
    "#                         LIMIT 1674896)\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clm = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{CFG.TRAIN_CLM_PATH}')\n",
    "                        )\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{CFG.TEST_PATH}')\n",
    "                        LIMIT 10000)\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def split_fold(df:pd.DataFrame):\n",
    "    # config\n",
    "    N_FOLDS = 5\n",
    "    RANDAM_SEED = 42\n",
    "    df['fold'] = -1\n",
    "\n",
    "    # object\n",
    "    skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(df)):\n",
    "        df.loc[test_index, 'fold'] = i\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_clm = split_fold(train_clm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>binds</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>bind1</th>\n",
       "      <th>bind2</th>\n",
       "      <th>bind3</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46212804</td>\n",
       "      <td>0.298898</td>\n",
       "      <td>0.215735</td>\n",
       "      <td>0.239334</td>\n",
       "      <td>0.034285</td>\n",
       "      <td>0.182660</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>-0.200705</td>\n",
       "      <td>0.449326</td>\n",
       "      <td>-0.123180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215490</td>\n",
       "      <td>-0.176117</td>\n",
       "      <td>0.369509</td>\n",
       "      <td>-0.111854</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61664237</td>\n",
       "      <td>0.382253</td>\n",
       "      <td>-0.172434</td>\n",
       "      <td>-0.062786</td>\n",
       "      <td>0.120820</td>\n",
       "      <td>-0.093798</td>\n",
       "      <td>0.520192</td>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.332013</td>\n",
       "      <td>-0.035972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>-0.133553</td>\n",
       "      <td>0.263715</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292563699</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>-0.260247</td>\n",
       "      <td>0.179049</td>\n",
       "      <td>0.162758</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.483988</td>\n",
       "      <td>-0.087336</td>\n",
       "      <td>0.153319</td>\n",
       "      <td>0.034525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034983</td>\n",
       "      <td>-0.334333</td>\n",
       "      <td>0.258336</td>\n",
       "      <td>-0.173001</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68335434</td>\n",
       "      <td>0.133682</td>\n",
       "      <td>-0.071265</td>\n",
       "      <td>0.217721</td>\n",
       "      <td>0.085580</td>\n",
       "      <td>-0.079135</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.190998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151728</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.198905</td>\n",
       "      <td>-0.346823</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142776429</td>\n",
       "      <td>-0.171107</td>\n",
       "      <td>0.095327</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.179870</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>0.240704</td>\n",
       "      <td>-0.268263</td>\n",
       "      <td>-0.235531</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>-0.400442</td>\n",
       "      <td>0.151702</td>\n",
       "      <td>-0.257879</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3         4         5  \\\n",
       "0   46212804  0.298898  0.215735  0.239334  0.034285  0.182660  0.425175   \n",
       "1   61664237  0.382253 -0.172434 -0.062786  0.120820 -0.093798  0.520192   \n",
       "2  292563699  0.065111 -0.260247  0.179049  0.162758  0.168346  0.483988   \n",
       "3   68335434  0.133682 -0.071265  0.217721  0.085580 -0.079135  0.571667   \n",
       "4  142776429 -0.171107  0.095327  0.110521  0.179870  0.173595  0.240704   \n",
       "\n",
       "          6         7         8  ...       380       381       382       383  \\\n",
       "0 -0.200705  0.449326 -0.123180  ... -0.215490 -0.176117  0.369509 -0.111854   \n",
       "1  0.141752  0.332013 -0.035972  ...  0.003045 -0.133553  0.263715 -0.389847   \n",
       "2 -0.087336  0.153319  0.034525  ... -0.034983 -0.334333  0.258336 -0.173001   \n",
       "3  0.020465  0.022752  0.190998  ... -0.151728  0.038851  0.198905 -0.346823   \n",
       "4 -0.268263 -0.235531  0.033824  ...  0.061882 -0.400442  0.151702 -0.257879   \n",
       "\n",
       "   binds  protein_name  bind1  bind2  bind3  fold  \n",
       "0      0          BRD4      0      0      0     0  \n",
       "1      0           sEH      0      0      0     3  \n",
       "2      0          BRD4      0      0      0     4  \n",
       "3      0          BRD4      0      0      0     0  \n",
       "4      0          BRD4      0      0      0     3  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>binds</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>bind1</th>\n",
       "      <th>bind2</th>\n",
       "      <th>bind3</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46212804</td>\n",
       "      <td>0.298898</td>\n",
       "      <td>0.215735</td>\n",
       "      <td>0.239334</td>\n",
       "      <td>0.034285</td>\n",
       "      <td>0.182660</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>-0.200705</td>\n",
       "      <td>0.449326</td>\n",
       "      <td>-0.123180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215490</td>\n",
       "      <td>-0.176117</td>\n",
       "      <td>0.369509</td>\n",
       "      <td>-0.111854</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61664237</td>\n",
       "      <td>0.382253</td>\n",
       "      <td>-0.172434</td>\n",
       "      <td>-0.062786</td>\n",
       "      <td>0.120820</td>\n",
       "      <td>-0.093798</td>\n",
       "      <td>0.520192</td>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.332013</td>\n",
       "      <td>-0.035972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>-0.133553</td>\n",
       "      <td>0.263715</td>\n",
       "      <td>-0.389847</td>\n",
       "      <td>0</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292563699</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>-0.260247</td>\n",
       "      <td>0.179049</td>\n",
       "      <td>0.162758</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.483988</td>\n",
       "      <td>-0.087336</td>\n",
       "      <td>0.153319</td>\n",
       "      <td>0.034525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034983</td>\n",
       "      <td>-0.334333</td>\n",
       "      <td>0.258336</td>\n",
       "      <td>-0.173001</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68335434</td>\n",
       "      <td>0.133682</td>\n",
       "      <td>-0.071265</td>\n",
       "      <td>0.217721</td>\n",
       "      <td>0.085580</td>\n",
       "      <td>-0.079135</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.190998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151728</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.198905</td>\n",
       "      <td>-0.346823</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142776429</td>\n",
       "      <td>-0.171107</td>\n",
       "      <td>0.095327</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.179870</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>0.240704</td>\n",
       "      <td>-0.268263</td>\n",
       "      <td>-0.235531</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>-0.400442</td>\n",
       "      <td>0.151702</td>\n",
       "      <td>-0.257879</td>\n",
       "      <td>0</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3         4         5  \\\n",
       "0   46212804  0.298898  0.215735  0.239334  0.034285  0.182660  0.425175   \n",
       "1   61664237  0.382253 -0.172434 -0.062786  0.120820 -0.093798  0.520192   \n",
       "2  292563699  0.065111 -0.260247  0.179049  0.162758  0.168346  0.483988   \n",
       "3   68335434  0.133682 -0.071265  0.217721  0.085580 -0.079135  0.571667   \n",
       "4  142776429 -0.171107  0.095327  0.110521  0.179870  0.173595  0.240704   \n",
       "\n",
       "          6         7         8  ...       380       381       382       383  \\\n",
       "0 -0.200705  0.449326 -0.123180  ... -0.215490 -0.176117  0.369509 -0.111854   \n",
       "1  0.141752  0.332013 -0.035972  ...  0.003045 -0.133553  0.263715 -0.389847   \n",
       "2 -0.087336  0.153319  0.034525  ... -0.034983 -0.334333  0.258336 -0.173001   \n",
       "3  0.020465  0.022752  0.190998  ... -0.151728  0.038851  0.198905 -0.346823   \n",
       "4 -0.268263 -0.235531  0.033824  ...  0.061882 -0.400442  0.151702 -0.257879   \n",
       "\n",
       "   binds  protein_name  bind1  bind2  bind3  fold  \n",
       "0      0          BRD4      0      0      0     0  \n",
       "1      0           sEH      0      0      0     3  \n",
       "2      0          BRD4      0      0      0     4  \n",
       "3      0          BRD4      0      0      0     0  \n",
       "4      0          BRD4      0      0      0     3  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>binds</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>bind1</th>\n",
       "      <th>bind2</th>\n",
       "      <th>bind3</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>81985115</td>\n",
       "      <td>0.267760</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>0.164821</td>\n",
       "      <td>-0.094532</td>\n",
       "      <td>0.485431</td>\n",
       "      <td>0.157744</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089555</td>\n",
       "      <td>-0.248966</td>\n",
       "      <td>0.285321</td>\n",
       "      <td>-0.347933</td>\n",
       "      <td>1</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>227438280</td>\n",
       "      <td>0.325959</td>\n",
       "      <td>-0.188691</td>\n",
       "      <td>0.099676</td>\n",
       "      <td>0.252709</td>\n",
       "      <td>-0.037638</td>\n",
       "      <td>0.579446</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0.089516</td>\n",
       "      <td>0.085101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062313</td>\n",
       "      <td>-0.155229</td>\n",
       "      <td>0.309876</td>\n",
       "      <td>-0.362709</td>\n",
       "      <td>1</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>62009222</td>\n",
       "      <td>0.337114</td>\n",
       "      <td>-0.080732</td>\n",
       "      <td>0.233315</td>\n",
       "      <td>0.319879</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.351365</td>\n",
       "      <td>-0.211420</td>\n",
       "      <td>0.025342</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387911</td>\n",
       "      <td>-0.392963</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>-0.261988</td>\n",
       "      <td>1</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>162837859</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>-0.336577</td>\n",
       "      <td>-0.020381</td>\n",
       "      <td>0.266737</td>\n",
       "      <td>0.073077</td>\n",
       "      <td>0.627532</td>\n",
       "      <td>0.134965</td>\n",
       "      <td>0.158673</td>\n",
       "      <td>-0.056279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095635</td>\n",
       "      <td>-0.438893</td>\n",
       "      <td>0.192547</td>\n",
       "      <td>-0.307759</td>\n",
       "      <td>1</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>36449071</td>\n",
       "      <td>0.375762</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>0.530286</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.089983</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074886</td>\n",
       "      <td>-0.066868</td>\n",
       "      <td>0.113061</td>\n",
       "      <td>-0.320741</td>\n",
       "      <td>1</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id         0         1         2         3         4         5  \\\n",
       "19995   81985115  0.267760 -0.205158  0.055440  0.164821 -0.094532  0.485431   \n",
       "19996  227438280  0.325959 -0.188691  0.099676  0.252709 -0.037638  0.579446   \n",
       "19997   62009222  0.337114 -0.080732  0.233315  0.319879  0.102618  0.351365   \n",
       "19998  162837859  0.350395 -0.336577 -0.020381  0.266737  0.073077  0.627532   \n",
       "19999   36449071  0.375762 -0.040645  0.166833  0.137244  0.009307  0.530286   \n",
       "\n",
       "              6         7         8  ...       380       381       382  \\\n",
       "19995  0.157744  0.006200  0.010068  ... -0.089555 -0.248966  0.285321   \n",
       "19996 -0.013899  0.089516  0.085101  ... -0.062313 -0.155229  0.309876   \n",
       "19997 -0.211420  0.025342 -0.010430  ... -0.387911 -0.392963  0.381071   \n",
       "19998  0.134965  0.158673 -0.056279  ... -0.095635 -0.438893  0.192547   \n",
       "19999  0.003918  0.089983  0.129359  ... -0.074886 -0.066868  0.113061   \n",
       "\n",
       "            383  binds  protein_name  bind1  bind2  bind3  fold  \n",
       "19995 -0.347933      1           sEH      0      0      1     1  \n",
       "19996 -0.362709      1          BRD4      1      0      0     2  \n",
       "19997 -0.261988      1           sEH      0      0      1     4  \n",
       "19998 -0.307759      1           HSA      0      1      0     0  \n",
       "19999 -0.320741      1           HSA      0      1      0     4  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_clm.head())\n",
    "display(train_clm.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train: pd.DataFrame,\n",
    "        label: pd.DataFrame = pd.DataFrame(),\n",
    "        is_test: bool = False,\n",
    "        transform = None\n",
    "    ):\n",
    "        self.train = train\n",
    "        self.label = label\n",
    "        self.is_test = is_test\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return total num of data\n",
    "        return len(self.train)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        # return data and target assosiated with index\n",
    "        X = self.train.iloc[index]\n",
    "        X = self._apply_transform(X)\n",
    "        \n",
    "        if self.is_test:\n",
    "            y = np.argmax(np.zeros(CFG.n_classes))\n",
    "            # y = [0, 0, 0]\n",
    "        else:\n",
    "            y = np.argmax(self.label.iloc[index].values)\n",
    "            # y = self.label.iloc[index].values\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_transform(self, X):\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim_model=384, # Model dimension d_model (embedding size)\n",
    "                 d_state=16, # SSM state expansion factor\n",
    "                 d_conv=4, # Local convolution width\n",
    "                 expand=2, # Block expansion factor\n",
    "                 output = 3 # number of classes (or output number simply)\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.model = Mamba(\n",
    "            d_model=dim_model,  \n",
    "            d_state=d_state,  \n",
    "            d_conv=d_conv,    \n",
    "            expand=expand,    \n",
    "        ).to(\"cuda\")\n",
    "        # mamba pass trought input size as is.\n",
    "        self.output = nn.Linear(dim_model, output)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the length dimension if input has only 2 dimensions\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "            \n",
    "        x = self.model(x)\n",
    "        x = self.output(x)\n",
    "        x = x.squeeze()\n",
    "        # x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### move tensors to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform values to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    return torch.tensor(x.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(CFG,\n",
    "                   val_fold: int,\n",
    "                   train: pd.DataFrame,\n",
    "                   output_path\n",
    "                   ):\n",
    "    feature_columns = [str(i) for i in range(384)]\n",
    "    label_columns = ['bind1', 'bind2', 'bind3']\n",
    "\n",
    "    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n",
    "    device = torch.device(CFG.device)\n",
    "    train_dataset = EXDataset(train = train[feature_columns][train['fold']!=val_fold].reset_index(drop=True), \n",
    "                              label = train[label_columns][train['fold']!=val_fold].reset_index(drop=True), \n",
    "                              transform = to_tensor)\n",
    "    val_dataset = EXDataset(train = train[feature_columns][train['fold']==val_fold].reset_index(drop=True), \n",
    "                            label = train[label_columns][train['fold']==val_fold].reset_index(drop=True), \n",
    "                            transform = to_tensor)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MambaModel()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer, epochs=CFG.max_epoch,\n",
    "        pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n",
    "    )\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss_func.to(device)\n",
    "    loss_func_val = nn.CrossEntropyLoss()\n",
    "\n",
    "    use_amp = CFG.enable_amp\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    best_val_loss = 1.0e+09\n",
    "    best_epoch = 0\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for epoch in range(1, CFG.max_epoch + 1):\n",
    "        epoch_start = time()\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            x, t = batch\n",
    "            # print(x)\n",
    "            # print(t)\n",
    "            x = to_device(x, device)\n",
    "            t = to_device(t, device).long()\n",
    "            # sys.exit()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            with amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "                loss = loss_func(y, t)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            scheduler.step()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "            \n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = to_device(x, device)\n",
    "            with torch.no_grad(), amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "#                 y = torch.sigmoid(y)\n",
    "            y = y.detach().cpu().to(torch.float32)\n",
    "            loss = loss_func_val(y, t)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = val_loss\n",
    "            # print(\"save model\")\n",
    "            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
    "        \n",
    "        elapsed_time = time() - epoch_start\n",
    "        print(\n",
    "            f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}\")\n",
    "        \n",
    "        if epoch - best_epoch > CFG.es_patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "            \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "            \n",
    "    return val_fold, best_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the above function actually, and save the best model of each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold0]\n",
      "[epoch 1] train loss:  0.710691, val loss:  0.640049, elapsed_time:  7.282\n",
      "[epoch 2] train loss:  0.622336, val loss:  0.617710, elapsed_time:  7.291\n",
      "[epoch 3] train loss:  0.588847, val loss:  0.614598, elapsed_time:  7.223\n",
      "[epoch 4] train loss:  0.561349, val loss:  0.586743, elapsed_time:  6.889\n",
      "[epoch 5] train loss:  0.533353, val loss:  0.559209, elapsed_time:  6.925\n",
      "[epoch 6] train loss:  0.506122, val loss:  0.549825, elapsed_time:  6.675\n",
      "[epoch 7] train loss:  0.482496, val loss:  0.551723, elapsed_time:  7.209\n",
      "[epoch 8] train loss:  0.459351, val loss:  0.549252, elapsed_time:  6.870\n",
      "[epoch 9] train loss:  0.444053, val loss:  0.547983, elapsed_time:  7.372\n",
      "[fold1]\n",
      "[epoch 1] train loss:  0.715195, val loss:  0.640740, elapsed_time:  6.689\n",
      "[epoch 2] train loss:  0.621290, val loss:  0.623129, elapsed_time:  7.091\n",
      "[epoch 3] train loss:  0.588694, val loss:  0.598158, elapsed_time:  7.105\n",
      "[epoch 4] train loss:  0.557465, val loss:  0.591780, elapsed_time:  7.316\n",
      "[epoch 5] train loss:  0.533614, val loss:  0.561058, elapsed_time:  7.260\n",
      "[epoch 6] train loss:  0.504060, val loss:  0.556488, elapsed_time:  7.213\n",
      "[epoch 7] train loss:  0.482656, val loss:  0.549749, elapsed_time:  7.108\n",
      "[epoch 8] train loss:  0.460113, val loss:  0.547795, elapsed_time:  6.728\n",
      "[epoch 9] train loss:  0.444253, val loss:  0.544969, elapsed_time:  6.839\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for fold_id in range(CFG.folds):\n",
    "    output_path = Path(f\"fold{fold_id}\")\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    print(f\"[fold{fold_id}]\")\n",
    "    score_list.append(train_one_fold(CFG, fold_id, train_clm, output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 9, 0.547982767470181), (1, 9, 0.5449692402929067)]\n"
     ]
    }
   ],
   "source": [
    "print(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete models without best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best model and delete others\n",
    "best_log_list = []\n",
    "for (fold_id, best_epoch, _) in score_list:\n",
    "    \n",
    "    # select the best model\n",
    "    exp_dir_path = Path(f\"fold{fold_id}\")\n",
    "    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
    "    # copy to new place\n",
    "    copy_to = f\"./best_model_fold{fold_id}.pth\"\n",
    "    shutil.copy(best_model_path, copy_to)\n",
    "    \n",
    "    for p in exp_dir_path.glob(\"*.pth\"):\n",
    "        # delete\n",
    "        p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_loop(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[0], device)\n",
    "            y = model(x)\n",
    "            pred_list.append(y.detach().cpu().numpy())\n",
    "    \n",
    "    # concatenate to vertical (to df that like long scroll)\n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do inference actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[fold 0]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\\n       ...\\n       '374', '375', '376', '377', '378', '379', '380', '381', '382', '383'],\\n      dtype='object', length=384)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_pred_arr\n\u001b[0;32m---> 29\u001b[0m test_preds_arr \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_clm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m, in \u001b[0;36minference\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(CFG\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m384\u001b[39m)]\n\u001b[0;32m---> 10\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m EXDataset(\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m, transform \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor())\n\u001b[1;32m     12\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# get model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\\n       ...\\n       '374', '375', '376', '377', '378', '379', '380', '381', '382', '383'],\\n      dtype='object', length=384)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def inference(train):\n",
    "    test_pred_arr = np.zeros((len(train), CFG.n_classes))\n",
    "    score_list = []\n",
    "\n",
    "    for fold_id in range(CFG.folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "        \n",
    "        feature_columns = [str(i) for i in range(384)]\n",
    "        test_dataset = EXDataset(test[feature_columns], transform = torch.tensor())\n",
    "    \n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "        # get model\n",
    "        model_path = f\"./best_model_fold{fold_id}.pth\"\n",
    "        model = MambaModel()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # inference\n",
    "        test_pred = run_inference_loop(model, test_loader, device)\n",
    "        test_pred_arr[fold_id] = test_pred\n",
    "\n",
    "        del val_idx, val_path_label\n",
    "        del model, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return test_pred_arr\n",
    "\n",
    "test_preds_arr = inference(train_clm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean each fold's predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_preds_arr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soon..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
