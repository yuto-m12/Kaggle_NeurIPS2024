{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastparquet -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import shutil\n",
    "from time import time\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "import duckdb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "from torch.nn import BCELoss\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import timm\n",
    "from mamba_ssm import Mamba\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# use one device only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20000_50per_CLM.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TRAIN_CLM_PATH = Path('../../data/processed/20000_50per_CLM.parquet')\n",
    "    TEST_ENC_PATH = Path('../../data/external/test_enc.parquet')\n",
    "    TRAIN_PATH = Path('../../data/raw/train.parquet')\n",
    "    TEST_PATH = Path('../../data/raw/test.parquet')\n",
    "    folds = 2\n",
    "    max_epoch = 9             # number of max epoch. 1epoch means going around the training dataset.\n",
    "    batch_size = 8           # batch size. Number of samples passed to the network in one training step\n",
    "    lr = 1.0e-03              # learning rate. determine step size when updating model's weight\n",
    "    weight_decay = 1.0e-02    # weight decay. Append regularization term for prevent over fitting\n",
    "    es_patience = 5           # Timing for early stopping. If there is no improvement within this number of epochs, training will be stopped early.\n",
    "    seed = 1086               # Random number seed\n",
    "    deterministic = True      # Enable/disable deterministic behavior. If enabled, the program will produce the same results every time it starts with the same initial conditions and inputs.\n",
    "    enable_amp = False        # Enable/disable Automatic Mixed Precision. Optimizations for floating point etc.\n",
    "    device = \"cuda\" \n",
    "    n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(CFG.TRAIN_ENC_PATH)\n",
    "# test = pd.read_parquet(CFG.TEST_ENC_PATH)\n",
    "# train.head()\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train.head())\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{CFG.TRAIN_PATH}')\n",
    "                        LIMIT 60000)\"\"\").df()\n",
    "# test = con.query(f\"\"\"(SELECT *\n",
    "#                         FROM parquet_scan('{CFG.TRAIN_ENC_PATH}')\n",
    "#                         LIMIT 1674896)\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clm = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{CFG.TRAIN_CLM_PATH}')\n",
    "                        )\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{CFG.TEST_PATH}')\n",
    "                        LIMIT 10000)\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def split_fold(df:pd.DataFrame):\n",
    "    # config\n",
    "    N_FOLDS = 5\n",
    "    RANDAM_SEED = 42\n",
    "    df['fold'] = -1\n",
    "\n",
    "    # object\n",
    "    skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(df)):\n",
    "        df.loc[test_index, 'fold'] = i\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_clm = split_fold(train_clm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_clm.head())\n",
    "display(train_clm.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train: pd.DataFrame,\n",
    "        label: pd.DataFrame = pd.DataFrame(),\n",
    "        is_test: bool = False,\n",
    "        transform = None\n",
    "    ):\n",
    "        self.train = train\n",
    "        self.label = label\n",
    "        self.is_test = is_test\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return total num of data\n",
    "        return len(self.train)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        # return data and target assosiated with index\n",
    "        X = self.train.iloc[index]\n",
    "        X = self._apply_transform(X)\n",
    "        \n",
    "        if self.is_test:\n",
    "            y = np.zeros(CFG.n_classes)\n",
    "            # y = [0, 0, 0]\n",
    "        else:\n",
    "            y = self.label.iloc[index].values\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_transform(self, X):\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim_model=384, # Model dimension d_model (embedding size)\n",
    "                 d_state=16, # SSM state expansion factor\n",
    "                 d_conv=4, # Local convolution width\n",
    "                 expand=2, # Block expansion factor\n",
    "                 output = 3 # number of classes (or output number simply)\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.model = Mamba(\n",
    "            d_model=dim_model,  \n",
    "            d_state=d_state,  \n",
    "            d_conv=d_conv,    \n",
    "            expand=expand,    \n",
    "        ).to(\"cuda\")\n",
    "        # mamba pass trought input size as is.\n",
    "        self.output = nn.Linear(dim_model, output)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the length dimension if input has only 2 dimensions\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "            \n",
    "        x = self.model(x)\n",
    "        logits = self.output(x)\n",
    "        prob = self.softmax(logits)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### move tensors to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform values to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    return torch.tensor(x.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(CFG,\n",
    "                   val_fold: int,\n",
    "                   train: pd.DataFrame,\n",
    "                   output_path\n",
    "                   ):\n",
    "    feature_columns = [str(i) for i in range(384)]\n",
    "    label_columns = ['bind1', 'bind2', 'bind3']\n",
    "\n",
    "    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n",
    "    device = torch.device(CFG.device)\n",
    "    train_dataset = EXDataset(train = train[feature_columns][train['fold']!=val_fold].reset_index(drop=True), \n",
    "                              label = train[label_columns][train['fold']!=val_fold].reset_index(drop=True), \n",
    "                              transform = to_tensor)\n",
    "    val_dataset = EXDataset(train = train[feature_columns][train['fold']==val_fold].reset_index(drop=True), \n",
    "                            label = train[label_columns][train['fold']==val_fold].reset_index(drop=True), \n",
    "                            transform = to_tensor)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MambaModel()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer, epochs=CFG.max_epoch,\n",
    "        pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n",
    "    )\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss_func.to(device)\n",
    "    loss_func_val = nn.CrossEntropyLoss()\n",
    "\n",
    "    use_amp = CFG.enable_amp\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    best_val_loss = 1.0e+09\n",
    "    best_epoch = 0\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for epoch in range(1, CFG.max_epoch + 1):\n",
    "        epoch_start = time()\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            x, t = batch\n",
    "            # print(x)\n",
    "            # print(t)\n",
    "            x = to_device(x, device)\n",
    "            t = to_device(t, device)\n",
    "            # sys.exit()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            with amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "                loss = loss_func(y, t)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Monitor memory usage\n",
    "            process = psutil.Process()\n",
    "            mem_info = process.memory_info()\n",
    "            print(f\"Epoch: {epoch}, Memory Usage: {mem_info.rss / (1024 * 1024)} MB\")\n",
    "\n",
    "            # Optional: sleep for a bit to avoid cluttering output\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "            \n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = to_device(x, device)\n",
    "            with torch.no_grad(), amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "#                 y = torch.sigmoid(y)\n",
    "            y = y.detach().cpu().to(torch.float32)\n",
    "            loss = loss_func_val(y, t)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = val_loss\n",
    "            # print(\"save model\")\n",
    "            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
    "        \n",
    "        elapsed_time = time() - epoch_start\n",
    "        print(\n",
    "            f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}\")\n",
    "        \n",
    "        if epoch - best_epoch > CFG.es_patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "            \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "            \n",
    "    return val_fold, best_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the above function actually, and save the best model of each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for fold_id in range(CFG.folds):\n",
    "    output_path = Path(f\"fold{fold_id}\")\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    print(f\"[fold{fold_id}]\")\n",
    "    score_list.append(train_one_fold(CFG, fold_id, train_clm, output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete models without best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best model and delete others\n",
    "best_log_list = []\n",
    "for (fold_id, best_epoch, _) in score_list:\n",
    "    \n",
    "    # select the best model\n",
    "    exp_dir_path = Path(f\"fold{fold_id}\")\n",
    "    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
    "    # copy to new place\n",
    "    copy_to = f\"./best_model_fold{fold_id}.pth\"\n",
    "    shutil.copy(best_model_path, copy_to)\n",
    "    \n",
    "    for p in exp_dir_path.glob(\"*.pth\"):\n",
    "        # delete\n",
    "        p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_loop(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[0], device)\n",
    "            y = model(x)\n",
    "            pred_list.append(y.detach().cpu().numpy())\n",
    "    \n",
    "    # concatenate to vertical (to df that like long scroll)\n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do inference actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(train):\n",
    "    test_pred_arr = np.zeros((len(train), CFG.n_classes))\n",
    "    score_list = []\n",
    "\n",
    "    for fold_id in range(CFG.folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "        \n",
    "        feature_columns = [str(i) for i in range(384)]\n",
    "        test_dataset = EXDataset(test[feature_columns], transform = torch.tensor())\n",
    "    \n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "        # get model\n",
    "        model_path = f\"./best_model_fold{fold_id}.pth\"\n",
    "        model = MambaModel()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # inference\n",
    "        test_pred = run_inference_loop(model, test_loader, device)\n",
    "        test_pred_arr[fold_id] = test_pred\n",
    "\n",
    "        del val_idx, val_path_label\n",
    "        del model, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return test_pred_arr\n",
    "\n",
    "test_preds_arr = inference(train_clm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean each fold's predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_preds_arr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soon..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
